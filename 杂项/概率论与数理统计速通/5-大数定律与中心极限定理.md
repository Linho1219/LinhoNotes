# 5 大数定律与中心极限定理

## 大数定律

### 依概率收敛

设 $Y_1,Y_2,\cdots,Y_n,\cdots$ 是随机变量序列，$Y$ 是随机变量，如果对于任意正数 $\varepsilon>0$，都有 $\lim\limits_{n\to\infty}P(|Y_n-Y|\ge\varepsilon)=0$，则称 $Y_n$ **依概率收敛于** $Y$，记作 $Y_n\xrightarrow PY$。

特别地，当 $Y$ 服从退化分布，即 $P(Y=c)=1$，称 $Y_n$ 依概率收敛于 $c$，记作 $Y_n\xrightarrow Pc$。

> [!note]
>
> $Y_n\xrightarrow PY$ 理解为：当样本容量 $n$ 充分大时，$Y_n$ 与 $Y$ 充分接近。
>
> 关于不依概率收敛到常数，而是依概率收敛到另一个随机变量的情况：完全可能出现，因为没说它们之间是相互独立的。例如有随机变量 $Y$（分布任意）和噪声源 $X\sim U(-1,1)$，有随机变量序列 $Y_i=Y+\dfrac1iX$，那就有 $Y_n\xrightarrow PY$。

### 两个概率不等式

**马尔可夫不等式**：对于**非负**随机变量 $X$，$\forall p,e>0$ 有

$$
P(X\ge\varepsilon)\le\frac{E(X^p)}{\varepsilon^p}
$$

**切比雪夫不等式**：对于**非负**随机变量 $X$，$\forall \varepsilon>0$ 有

$$
P(|X-E(X)|\ge\varepsilon)\le\frac{\operatorname {Var}(x)}{\varepsilon^2}
$$

> [!note]
>
> **理解两个不等式**
>
> 取 $p=1$，马尔可夫不等式在说：对于非负随机变量 $X$，如果知道了均值 $\mu$，能约束它“大得离谱”的概率。
>
> 上界怎么来的？来源于**非负**。要让 $P(X\ge\varepsilon)$ 最大，那让 $X\ge\varepsilon$ 的部分尽可能小，取 $\varepsilon$；其余部分也尽可能小，取 $0$。那要维持均值 $\mu$，就有 $\varepsilon P(X\ge\varepsilon)+0=\mu$，自然得到这个概率是 $\dfrac\mu\varepsilon$。
>
> 完整版再加个 $p$ 次方。
>
> ---
>
> 切比雪夫不等式在说：知道方差 $\sigma^2$，就能约束偏离均值的概率。偏离 $\varepsilon$ 的概率不会超过 $\dfrac{\sigma^2}{\varepsilon^2}$。
>
> 切比雪夫不等式是马尔可夫不等式中取 $p=2$ 并用 $X-\mu$ 替代 $X$ 得到的。

### 大数定律

设有随机变量 $X_1,X_2,\cdots,X_n,\cdots$，记 $\bar X=\dfrac1n\sum\limits_{i=0}^nX_i$，如果满足 $\bar X-E(\bar X)\xrightarrow P0$，称随机变量序列 $X_1,X_2,\cdots,X_n,\cdots$ 服从大数定律。

**马尔可夫大数定律**：如果随机变量序列满足 $\lim\limits_{n\to\infty}\dfrac1{n^2}\operatorname {Var}\left(\sum\limits_{i=1}^nX_i\right)=0$，则服从大数定律。

**辛钦大数定律**：独立同分布的随机变量序列，只要期望存在，就服从大数定律。

> [!note]
>
> **理解大数定律**
>
> 对于**独立同分布**的变量 $X_1,X_2,\cdots,X_n,\cdots$，设每次期望是 $\mu$，方差是 $\sigma^2$。考虑其样本均值 $\bar X$，随着次数 $n$ 的增大：
>
> - 均值期望不会变：$E(\bar X)=\mu$
> - 均值方差会变小：$\operatorname {Var}(\bar X)=\dfrac{\sigma^2}n$
>
> 根据切比雪夫不等式，$\bar X$ 偏离均值 $\varepsilon$ 的概率不会超过 $\dfrac{\sigma^2}{n\varepsilon^2}$。当 $n\to\infty$ 时这个概率 $\to0$。也就是说 $\bar X\xrightarrow P\mu$，服从大数定律。
>
> 核心就在于均值方差在随着 $\dfrac1n$ 变小，$n\to\infty$ 的时候就彻底退化到 $0$ 了。
>
> **如果不是独立同分布，那「均值方差 $\to0$」这件事就只能靠增加条件来约束了。**

## 中心极限定理

### 按分布收敛

设随机变量 $Y,Y_1,Y_2,\cdots,Y_n,\cdots$ 的分布函数 $F(x),F_1(x),F_2(x),\cdots,F_n(x),\cdots$，若对 $F(x)$ 的任一连续点 $x$ 都有 $\lim\limits_{n\to\infty}F_n(x)=F(x)$，则称随机变量序列 $Y_1,Y_2,\cdots,Y_n,\cdots$ **按分布收敛于**随机变量 $Y$，记作 $Y_n\xrightarrow LY$。

> [!tip]
>
> 也可以写「按分布收敛于某一分布」，例如 $X\xrightarrow LN(0,1)$。

### 中心极限定理

中心极限定理是指这样的**一类结论**：在某些条件下，会有

$$
(\bar X)^*
=({\textstyle\sum} X_i)^*
=\frac{\sum X_i-E(\sum X_i)}{\sigma(\sum X_i)}
\xrightarrow LN(0,1)
$$

只介绍其中的一个。

**林德伯格-莱维中心极限定理**：对于**独立同分布**随机变量 $X_1,\cdots,X_n,\cdots$，有 $E(X_1)=\mu$，$\operatorname {Var}(X_1)=\sigma^2$，则

$$
Y_n=\frac{\bar X-\mu}{\sigma/\sqrt n}\xrightarrow LN(0,1)
$$
